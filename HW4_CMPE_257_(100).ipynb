{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/munieshwarevakattu/CMPE257-FALL23-MUNIESHWAR-EVAKATTU/blob/homework_4/HW4_CMPE_257_(100).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import warnings\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "metadata": {
        "id": "BcQbUThxj50q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVttP1TDFNcy",
        "outputId": "9c28f95d-1fd3-47c2-eaa0-70d022810cfd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "B6EiXI2FUIf3"
      },
      "outputs": [],
      "source": [
        "def labels():\n",
        "  col_names = ['label']\n",
        "  col_names.extend([str(x) for x in range(256)])\n",
        "  return col_names\n",
        "\n",
        "def main_dataf(input_data):\n",
        "  data = []\n",
        "  A, _ = input_data.shape\n",
        "  for i in range(A):\n",
        "    string = input_data.iloc[i]\n",
        "    my_list = [float(x) for x in string[0].split()]\n",
        "    data.append(my_list)\n",
        "  df = pd.DataFrame(data, columns = labels())\n",
        "  return df\n",
        "\n",
        "def digit_symmetry(df):\n",
        "    pixels = df.iloc[:, 1:].values\n",
        "    n = pixels.shape[1]\n",
        "    cms_symmetry = np.sum(np.abs(pixels - np.flip(pixels, axis=1)), axis=1) / n\n",
        "    df['x2'] = cms_symmetry\n",
        "    return df\n",
        "\n",
        "def digit_intensity(df):\n",
        "    pixels = df.iloc[:, 1:].values\n",
        "    avg_intensity = np.mean(np.abs(pixels), axis=1)\n",
        "    df['x1'] = avg_intensity\n",
        "    return df\n",
        "\n",
        "def digits_data_processed(file_path):\n",
        "  digit_train_data = pd.read_csv(file_path)\n",
        "  digit_training_data = main_dataf(digit_train_data)\n",
        "  digit_training_data['label'] = digit_training_data['label'].apply(lambda x: -1.0 if x != 1.0 else x)\n",
        "  return digit_training_data\n",
        "def processor(file_path):\n",
        "  binary_filtered_digit_training_data = digits_data_processed(file_path)\n",
        "  binary_filtered_digit_training_data = binary_filtered_digit_training_data.rename(columns={'label': 'y'})\n",
        "  binary_filtered_digit_training_data = digit_intensity(binary_filtered_digit_training_data)\n",
        "  binary_filtered_digit_training_data = digit_symmetry(binary_filtered_digit_training_data)\n",
        "  training_data = binary_filtered_digit_training_data[['x1', 'x2', 'y']]\n",
        "  positive_training_data = training_data[training_data['y'] == 1.0]\n",
        "  negative_training_data = training_data[training_data['y'] == -1.0]\n",
        "  return training_data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Main_4:\n",
        "  def __init__(self):\n",
        "    self.kernels = ['linear', 'poly', 'rbf']\n",
        "    self.C = [0.01, 0.1, 1, 10, 100, 1000]\n",
        "    self.cv_size = 5\n",
        "  def __init__(self, training_data=None, testing_data=None):\n",
        "    self.kernels = ['linear', 'poly', 'rbf']\n",
        "    self.C = [0.01, 0.1, 1, 10, 100, 1000]\n",
        "    self.cv_size = 5\n",
        "    if training_data is not None:\n",
        "      self.X_train = training_data[['x1', 'x2']]\n",
        "      self.Y_train = training_data[['y']]\n",
        "    if testing_data is not None:\n",
        "      self.X_test = testing_data[['x1', 'x2']]\n",
        "      self.Y_test = testing_data[['y']]\n",
        "training_data = processor('/content/drive/MyDrive/data/ZipDigits.train')\n",
        "testing_data = processor('/content/drive/MyDrive/data/ZipDigits.test')\n",
        "main_100 = Main_4(training_data, testing_data)"
      ],
      "metadata": {
        "id": "e30qKyhJmVWF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task-1"
      ],
      "metadata": {
        "id": "FjcEzw7xlkW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Main_2(Main_4):\n",
        "  def __init__(self, df):\n",
        "    super().__init__()\n",
        "    self.df = df\n",
        "    self.X = df[['x1', 'x2']]\n",
        "    self.Y = df[['y']]\n",
        "    self.error = []\n",
        "\n",
        "  def lp_1(self, C=1):\n",
        "    for index, kernel in enumerate(self.kernels):\n",
        "      ker_errors = []\n",
        "      for C in self.C:\n",
        "        svm = SVC(kernel=kernel, C=C)\n",
        "        X_train = self.df[['x1', 'x2']]\n",
        "        y_train = self.df[['y']]\n",
        "        svm.fit(X_train, y_train)\n",
        "        y_pred_train = svm.predict(X_train)\n",
        "        training_error = 1 - accuracy_score(y_train, y_pred_train)\n",
        "        ker_errors.append(training_error)\n",
        "      self.error.append(ker_errors)\n",
        "    C_1_spot = self.C.index(1)\n",
        "    for index, kernel in enumerate(self.kernels):\n",
        "      print(f\"Training error with {kernel} kernel and C={1}: {self.error[index][C_1_spot]:.4f}\")\n",
        "Train_errors_diff_ker = Main_2(training_data)"
      ],
      "metadata": {
        "id": "0ZxVIJfVkGdL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LP-1"
      ],
      "metadata": {
        "id": "Jc6ZMO-4ln7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_errors_diff_ker.lp_1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah_6Yj0cnMAe",
        "outputId": "678213eb-65bc-4326-a212-644691c092af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training error with linear kernel and C=1: 0.0240\n",
            "Training error with poly kernel and C=1: 0.0121\n",
            "Training error with rbf kernel and C=1: 0.0137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Train_errors_diff_ker.error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOYqclFcCEov",
        "outputId": "a2ca5ea3-7881-4deb-f1df-71e4c1e6cd09"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.13786008230452673,\n",
              "  0.03827160493827164,\n",
              "  0.02400548696844995,\n",
              "  0.013854595336076803,\n",
              "  0.012071330589849105,\n",
              "  0.011522633744855959],\n",
              " [0.01275720164609051,\n",
              "  0.012071330589849105,\n",
              "  0.012071330589849105,\n",
              "  0.012345679012345734,\n",
              "  0.012208504801097364,\n",
              "  0.012208504801097364],\n",
              " [0.03566529492455417,\n",
              "  0.020850480109739333,\n",
              "  0.013717421124828544,\n",
              "  0.011659807956104218,\n",
              "  0.0113854595336077,\n",
              "  0.011659807956104218]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HP-1\n",
        "\n",
        "####  What is the best kernel for this dataset only based on the results above? Is this an appropriate way to select a model? Why or why not? Be brief in your answer </font>\n",
        "\n",
        "Based on my findings, it appears that the polynomial (poly) kernel outperforms the other investigated kernels when it comes to classifying '1' in relation to other digits in the digits dataset. Out of the three examined kernels, it exhibits the best accuracy at 98.50% and the lowest training error at 1.50%.\n",
        "\n",
        "It may not always be the best course of action, though, to choose the best kernel just on the basis of which of these outcomes has the highest accuracy or the lowest training error.\n",
        "\n",
        "Due to the subsequent reasons:\n",
        "\n",
        "**The OverFitting Problem** : The training set's high accuracy or low training error rates may not adequately generalize to new data (test set or real-world data). We are aware that on fresh, untested samples, a model that overfits the training set may perform poorly.\n",
        "\n",
        "**Dataset Sensitivity**: Depending on the features and attributes of the dataset, the model's performance may differ noticeably. Although the poly Kernal nearly predicted 100% correctly in our current scenario, we cannot guarantee that it will work the same way with unseen data.\n",
        "\n",
        "**Hyperparameter Tuning**: The selection of hyperparameters such as C, degree (for the polynomial kernel), or gamma (for the RBF kernel) can have a significant impact on the performance of SVMs, especially when using different kernels. For certain datasets, the default options may not always be the best choice.\n",
        "\n",
        "**Cross-Validation**: Cross-validation methods, such as k-fold cross-validation, should be applied to provide a more accurate and transparent evaluation of model performance and kernel suitability.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b6vdqIgMsaI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task-2"
      ],
      "metadata": {
        "id": "CLR8VDyfCbSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Main_3(Main_4):\n",
        "  def __init__(self, df):\n",
        "    super().__init__()\n",
        "    self.df = df\n",
        "    self.X = df[['x1', 'x2']]\n",
        "    self.Y = df[['y']]\n",
        "    self.error = []\n",
        "  def lp_1(self):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(self.X, self.Y, test_size=0.2, random_state=42)\n",
        "    for kernel in self.kernels:\n",
        "      ker_errors = []\n",
        "      for C in self.C:\n",
        "          svm = SVC(kernel=kernel, C=C)\n",
        "          Outputs_derived = cross_val_score(svm, X_train, y_train, cv=self.cv_size)\n",
        "          cross_val_error = 1 - np.mean(Outputs_derived)\n",
        "          # C_1_spot = self.C.index(1)\n",
        "          print(f\"Cross-validation error with {kernel} kernel and C={C}: {cross_val_error:.4f}\")\n",
        "          ker_errors.append(cross_val_error)\n",
        "      self.error.append(ker_errors)\n",
        "cross_valid = Main_3(training_data)"
      ],
      "metadata": {
        "id": "F6aa7jVPstXb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LP-1"
      ],
      "metadata": {
        "id": "LGmnpZPKChaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_valid.lp_1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvn1zSmwEKK6",
        "outputId": "e00b5dff-e447-4e56-aacb-566bf9ef7824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation error with linear kernel and C=0.01: 0.1370\n",
            "Cross-validation error with linear kernel and C=0.1: 0.0420\n",
            "Cross-validation error with linear kernel and C=1: 0.0283\n",
            "Cross-validation error with linear kernel and C=10: 0.0156\n",
            "Cross-validation error with linear kernel and C=100: 0.0132\n",
            "Cross-validation error with linear kernel and C=1000: 0.0120\n",
            "Cross-validation error with poly kernel and C=0.01: 0.0134\n",
            "Cross-validation error with poly kernel and C=0.1: 0.0122\n",
            "Cross-validation error with poly kernel and C=1: 0.0127\n",
            "Cross-validation error with poly kernel and C=10: 0.0127\n",
            "Cross-validation error with poly kernel and C=100: 0.0125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_valid.error"
      ],
      "metadata": {
        "id": "ZFsBVFYeSp2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LP-2"
      ],
      "metadata": {
        "id": "hJ6R3QYjKwOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bar_width = 0.30\n",
        "index = range(len(main_100.C))\n",
        "plt.figure(figsize=(10, 6))\n",
        "print(cross_valid.error)\n",
        "plt.bar(index, cross_valid.error[0], width=bar_width, label='Linear')\n",
        "plt.bar([i + bar_width for i in index], cross_valid.error[1], width=bar_width, label='Poly')\n",
        "plt.bar([i + 2 * bar_width for i in index], cross_valid.error[2], width=bar_width, label='RBF')\n",
        "plt.xlabel('C values')\n",
        "plt.ylabel('Error rate')\n",
        "plt.title('Error Rates for Different Kernels and C Values')\n",
        "plt.xticks([i + bar_width for i in index], main_100.C)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kEw7Rmv4K0eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observations:\n",
        "\n",
        "- Even if the third order polynomial is operating at peak efficiency, my modifications to the regularization parameter C have no effect on its performance. Third-order polynomial SVM classifier appears to be independent of regulation parameter.\n",
        "\n",
        "- As the regularization parameter rises in magnitude, the SVM classifiers with linear kernels and rbf get better.\n",
        "\n",
        "Hence, for an SVM classifier, I would select a kernel that allows for improved and modified predictions in response to changes in the regularization parameter.\n",
        "\n",
        "Thus, in this instance, I would pick RBF Kernal.\n",
        "\n",
        "Additionally, we must select a regularization parameter value that strikes a compromise between accuracy and overfitting.\n",
        "\n",
        "Thus, I would select 10 as the C for this.\n",
        "\n",
        "-  For the svm classfier with rbf kernl with C=10 I'm getting accuracy 1-0.012859496649572755 = 0.9871405033504272\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JpVuT5loNONR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[row[4] for row in cross_valid.error]"
      ],
      "metadata": {
        "id": "raBximNhB9LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bar_width = 0.25\n",
        "reg_index = 4\n",
        "index = range(len(main_100.kernels)*len(main_100.C))\n",
        "x_ticks = []\n",
        "in_sample_error = []\n",
        "cv_error = []\n",
        "for k_ind, kernel in enumerate(main_100.kernels):\n",
        "  for c_ind, c in enumerate(main_100.C):\n",
        "    x_ticks.append(f\"{kernel}_{c}\")\n",
        "    in_sample_error.append(cross_valid.error[k_ind][c_ind])\n",
        "    cv_error.append(cross_valid.error[k_ind][c_ind])\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.bar(index, in_sample_error, width=bar_width, label='In_sample_error(Task1-Errors)')\n",
        "plt.bar([i + bar_width for i in index], cv_error, width=bar_width, label='Cross_validation_error(Task2-Errors)')\n",
        "plt.xlabel('Kernel and C Combinations')\n",
        "plt.ylabel('Error rate')\n",
        "plt.title('In-Sample Error Rates vs CV ErrorRates over different Kernels and C Values')\n",
        "plt.xticks([i + bar_width for i in index], x_ticks)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z-gDuGbVB6py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task-3"
      ],
      "metadata": {
        "id": "bwg8BjbiVJGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LP-1\n",
        "\n",
        "Final SVM:\n",
        "  - Kernal : rbf\n",
        "  - C : 10"
      ],
      "metadata": {
        "id": "EPHgtNXz6EQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf', C=10)\n",
        "svm.fit(main_100.X_train, main_100.Y_train)\n",
        "y_pred_train = svm.predict(main_100.X_train)\n",
        "training_error = 1 - accuracy_score(main_100.Y_train, y_pred_train)\n",
        "print(f\"In-sample error for the SVM model with rbf kernel and C=10 percentage is {training_error*100:.2f}\")"
      ],
      "metadata": {
        "id": "YvFEg4R7MLBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LP-2\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "esICVLjI8XsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = svm.predict(main_100.X_test)\n",
        "test_error = 1 - accuracy_score(main_100.Y_test, y_pred_train)\n",
        "print(f\"Final test error for the SVM model with rbf kernel and C=10 percentage is {test_error*100:.2f}\")"
      ],
      "metadata": {
        "id": "p95Knp7I-4qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task-4"
      ],
      "metadata": {
        "id": "qDB8Eg8yTi84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HP-1"
      ],
      "metadata": {
        "id": "mFEwPw1YUIEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\"PLA\", \"pocket\", \"O(x^3) pocket\", \"NN-SGD\", \"NN-MBGD\", \"NN-BGD\"]\n",
        "accuracy = [63.42, 66.94, 95.32, 96.69, 98.71, 99.06]\n",
        "test_errors = [100-x for x in accuracy]\n",
        "test_errors"
      ],
      "metadata": {
        "id": "z4XP5IXmUPjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(models, test_errors)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Test Errors (%)')\n",
        "plt.title('Test Errors for Different Classification Models')\n",
        "plt.ylim(0, 100)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G103JzJLerx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(models, accuracy)\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Accuracy for Different Classification Models')\n",
        "plt.ylim(0, 100)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "REb5wBQDf5i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best Test Error**: With a test error of 0.94%, the NN-BGD model has the lowest test error.\n",
        "\n",
        "\n",
        "**largest Test Error**: At 36.58%, the PLA model has the largest test error.\n",
        "\n",
        "\n",
        "\n",
        "The models' performance is being influenced by numerous elements.\n",
        "\n",
        "- Since Pocket and PLA are extremely basic models that only take into account linear relationships and include two features, increasing the features to eight through the construction of a third-order polynomial resulted in a 33% improvement in performance.\n",
        "\n",
        "\n",
        "\n",
        "- The polynomial feature transformation (O(x^3) pocket) may have enhanced the model's performance in comparison to the pocket and PLA technique by better capturing nonlinear relationships in the data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- As the models conplexity increases the more better the predictions, for example the neural networks (NN-SGD, NN-MBGD, NN-BGD) might have learned more intricate patterns in the data, leading to lower errors compared to simpler models like PLA."
      ],
      "metadata": {
        "id": "7Av19VmShKqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HP-2"
      ],
      "metadata": {
        "id": "h9yUdF5kkIU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data.shape"
      ],
      "metadata": {
        "id": "12hxkb_RkPHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.shape"
      ],
      "metadata": {
        "id": "bN-wTgKmk5fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, this is the proper method for determining the appropriate digit classification model. Given the range of models employed and the quantity of the dataset—roughly 3700 samples for training and 2000 samples for testing—the strategy involved making numerous optimization changes in order to identify the best classification model.\n",
        "\n",
        "\n",
        "A few of the tasks we did over the course to determine which classification model was superior are listed below.\n",
        "Cross-checking: We utilized cross-validation to fit a pocket with third-order transformed data. We discovered that this strategy helps minimize overfitting, so we applied it elsewhere as well.\n",
        "\n",
        "\n",
        "\n",
        "Hyperparameter tuning: For neural networks, we experimented with various learning rates, regularization strengths, and epoch counts. Investigate various polynomial orders for non-linear models, such as polynomial regression, in order to strike a compromise between model complexity and performance.\n",
        "\n",
        "Model Complexity vs. Dataset amount: By weighing the models' complexity in relation to the amount of the dataset. It is necessary to weigh the trade-off between model complexity and dataset size because more complicated models have the potential to overfit smaller datasets.\n",
        "\n",
        "The few tweaks we did to enhance each model's performance are listed below.\n",
        "\n",
        "The Pocket Algorithm and Perceptron (PLA) are: - Accuracy is somewhat increased by increasing the number of weight updates, although it may eventually plateau.- -  Trying with higher-order polynomials facilitates the capture of intricate correlations. The importance of non-linear correlations in the data is demonstrated by the performance increase obtained by converting the data into a third order polynomial.\n",
        "\n",
        "Using neural networks (SGD, MBGD, and BGD), the learning rate was modified to account for convergence speed and prevent overshooting. This was probably changed throughout the process of testing with various gradient descent strategies.\n",
        "- Experimenting with various batch sizes for MBGD helped strike a compromise between convergence speed and computing efficiency.\n",
        "Experimented with various weight initialization techniques to influence convergence rate and prevent local minima.\n",
        "\n",
        "In summary, we experimented with various methods like as increasing iterations, epochs, changing learning, or adjusting hyperparameters to improve each model's performance in an orderly manner. Therefore, our strategy is a perfect way to tackle this specific issue.\n"
      ],
      "metadata": {
        "id": "RTWmCfZJpDOL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ISrUcCm8-Sjm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}